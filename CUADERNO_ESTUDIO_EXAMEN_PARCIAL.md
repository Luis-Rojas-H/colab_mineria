# ğŸ“š CUADERNO DE ESTUDIO - EXAMEN PARCIAL CC442
## MinerÃ­a de Datos (8vo Ciclo)

**Fecha:** 2025  
**Profesor:** Basado en teorÃ­a del curso  
**Temas:** Naive Bayes, RegresiÃ³n Lineal, Linear Discriminant Analysis

---

## ğŸ“‹ ÃNDICE DEL CUADERNO

1. [TeorÃ­a de Algoritmos de ClasificaciÃ³n](#teorÃ­a)
2. [Problema 1: Automobile Accidents](#problema-1)
3. [Problema 2: Toyota Corolla Prices](#problema-2)
4. [Problema 3: Spam Detection](#problema-3)
5. [Resumen de EvaluaciÃ³n](#resumen)
6. [Preguntas de Examen Probable](#preguntas)

---

## <a name="teorÃ­a"></a>
# PARTE 1: TEORÃA FUNDAMENTAL

## 1.1 Naive Bayes - Fundamentos

### Â¿QuÃ© es Naive Bayes?

**DefiniciÃ³n:** Algoritmo de clasificaciÃ³n probabilÃ­stico basado en el Teorema de Bayes que asume independencia condicional entre predictores.

**FÃ³rmula clave:**
```
P(Clase | CaracterÃ­sticas) âˆ P(CaracterÃ­sticas | Clase) Ã— P(Clase)
```

### Â¿Por quÃ© se llama "Naive" (Ingenuo)?

Porque **asume independencia entre predictores** aunque en realidad pueden estar correlacionados.

**Ejemplo:**
```
En un email:
- P(palabra "dinero" | spam)
- P(palabra "gratis" | spam)
- P(palabra "urgente" | spam)

Naive Bayes ASUME que estas palabras son independientes
P(dinero, gratis, urgente | spam) = P(dinero|spam) Ã— P(gratis|spam) Ã— P(urgente|spam)

En realidad, los spams que mencionan "dinero" tambiÃ©n tienden a mencionar "gratis"
(correlacionadas), pero el algoritmo ignora esto.

Â¡Y funciona bien de todas formas! (sorprendentemente)
```

### Variantes de Naive Bayes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TIPO                â”‚ DATOS IDEALES      â”‚ FÃ“RMULA         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Multinomial NB      â”‚ Datos discretos    â”‚ Conteos         â”‚
â”‚ (FlightDelays)      â”‚ Palabras/conteos   â”‚ (para spam)     â”‚
â”‚                     â”‚                    â”‚                 â”‚
â”‚ Gaussian NB         â”‚ Datos continuos    â”‚ DistribuciÃ³n    â”‚
â”‚                     â”‚ Distribuidos       â”‚ gaussiana       â”‚
â”‚                     â”‚ normalmente        â”‚                 â”‚
â”‚                     â”‚                    â”‚                 â”‚
â”‚ Bernoulli NB        â”‚ Variables binarias â”‚ 0/1 solamente   â”‚
â”‚                     â”‚ (presencia/ausencia)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Â¿Por quÃ© Multinomial NB necesita datos DISCRETOS?

**Problema con datos continuos:**

Si una variable es continua (e.g., edad = 34.567 aÃ±os):
- En el dataset de entrenamiento, probablemente NO se repetirÃ¡ exactamente 34.567
- El algoritmo contarÃ­a: 1 o 0 ocurrencias (muy poco confiable)
- P(edad=34.567 | retraso) serÃ­a imposible de calcular correctamente

**SoluciÃ³n - Convertir a discreta:**

```python
# OPCIÃ“N 1: Binning manual
df['edad_categoria'] = pd.cut(df['edad'], bins=[0, 18, 30, 45, 65, 100])
# Resultado: edad_0_18, edad_18_30, edad_30_45, edad_45_65, edad_65_100

# OPCIÃ“N 2: One-Hot Encoding (como en el examen)
X = pd.get_dummies(df[['WEATHER_R', 'TRAF_CON_R']])
# Resultado: WEATHER_R_0, WEATHER_R_1, WEATHER_R_2, TRAF_CON_R_0, etc.

# OPCIÃ“N 3: Usar GaussianNB (para datos continuos)
from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_continuo, y)
```

### Laplace Smoothing (ParÃ¡metro alpha)

**Problema sin smoothing:**

```
Si "CARRIER=XYZ" nunca aparece en los vuelos retrasados del training:
P(CARRIER=XYZ | delayed) = 0 / total = 0

Cuando llegue un vuelo real con XYZ:
P(delayed | XYZ) = 0 (Â¡nunca predecirÃ¡ delayed!)
```

**SoluciÃ³n - Laplace Smoothing:**

```
P(caracterÃ­stica | clase) = (conteos + Î±) / (total + Î± Ã— V)

donde:
- Î± = parÃ¡metro de suavizado (tÃ­picamente 1.0 o 0.01)
- V = nÃºmero de valores Ãºnicos de la caracterÃ­stica

Ejemplo:
P(CARRIER=XYZ | delayed) = (0 + 0.01) / (1000 + 0.01Ã—100) = 0.01 / 1001

Â¡Ahora NO es cero! (pequeÃ±a probabilidad que permite predicciÃ³n)
```

---

## 1.2 RegresiÃ³n Lineal MÃºltiple

### Concepto Fundamental

**Objetivo:** Predecir una variable continua (precio) usando mÃºltiples predictores.

**Modelo:**
```
y = Î²â‚€ + Î²â‚Ã—xâ‚ + Î²â‚‚Ã—xâ‚‚ + ... + Î²â‚™Ã—xâ‚™ + Îµ

donde:
- y = variable objetivo (Price)
- Î²â‚€ = intercepto
- Î²â‚, Î²â‚‚, ..., Î²â‚™ = coeficientes
- xâ‚, xâ‚‚, ..., xâ‚™ = predictores
- Îµ = error residual
```

### InterpretaciÃ³n de Coeficientes

```
Si el coeficiente de "Edad" es -500:
"Cada aÃ±o adicional de edad â†’ DISMINUYE el precio en $500"

Si el coeficiente de "HP" es 100:
"Cada caballode fuerza adicional â†’ AUMENTA el precio en $100"
```

### EvaluaciÃ³n del Modelo

**RÂ² (Coeficiente de DeterminaciÃ³n):**
```
RÂ² = 1 - (SS_residual / SS_total)

Rango: 0 a 1 (o 0% a 100%)

InterpretaciÃ³n:
- RÂ² = 0.85 â†’ El modelo explica 85% de la varianza
- RÂ² = 0.50 â†’ Explicamos solo 50% (malo)
- RÂ² = 0.95 â†’ Explicamos 95% (excelente)
```

**RMSE (Root Mean Squared Error):**
```
RMSE = âˆš(Î£(y_real - y_predicciÃ³n)Â² / n)

InterpretaciÃ³n:
- Unidades: Mismas que la variable objetivo (ej: dÃ³lares)
- RMSE = $2000 â†’ En promedio, nuestras predicciones estÃ¡n $2000 de error
```

---

## 1.3 Linear Discriminant Analysis (LDA)

### Concepto

**Objetivo:** ClasificaciÃ³n que busca encontrar una combinaciÃ³n lineal de caracterÃ­sticas que mejor separe las clases.

**Idea visual:**

```
Sin LDA:                    Con LDA:
Clase A: â—â—â—             Proyectado en LD1:
Clase B: â—‹â—‹â—‹             â—â—â— | â—‹â—‹â—‹
         (datos           (mejor separaciÃ³n)
          mezclados)
```

### Ventajas de LDA

```
âœ“ Funciona bien con datos multidimensionales
âœ“ Computacionalmente eficiente
âœ“ Proporciona matriz de proyecciÃ³n
âœ“ Tiene en cuenta estructura de covarianza
âœ“ No requiere muchos parÃ¡metros de tuning
```

### Matriz de ConfusiÃ³n en ClasificaciÃ³n Binaria

```
                    PredicciÃ³n
                Spam    No-Spam
    Real Spam      TP        FN
    Real No-Spam   FP        TN

Donde:
- TP (True Positive): Predijo spam, era spam âœ“
- FP (False Positive): Predijo spam, era no-spam âœ— (falsa alarma)
- FN (False Negative): Predijo no-spam, era spam âœ— (se colÃ³ el spam)
- TN (True Negative): Predijo no-spam, era no-spam âœ“
```

### MÃ©tricas de EvaluaciÃ³n

```
Accuracy = (TP + TN) / Total
â†’ Porcentaje total correcto

Precision = TP / (TP + FP)
â†’ De los que predicho como SPAM, Â¿cuÃ¡ntos realmente lo eran?
â†’ Evita falsas alarmas

Recall (Sensitivity) = TP / (TP + FN)
â†’ De los SPAM reales, Â¿cuÃ¡ntos detectÃ©?
â†’ Capacidad de detectar positivos

Specificity = TN / (TN + FP)
â†’ De los NO-SPAM, Â¿cuÃ¡ntos identifico correctamente?
```

---

# <a name="problema-1"></a>
# PROBLEMA 1: AUTOMOBILE ACCIDENTS

## Objetivo

Predecir si un accidente automovilÃ­stico involucrarÃ¡ lesiÃ³n (INJURY = yes/no) usando Naive Bayes.

## Datos

```
Dataset: AccidentsFull.csv
- 42,183 registros
- Accidentes en USA, aÃ±o 2001
- InformaciÃ³n: clima, trÃ¡fico, carretera, etc.

Variable objetivo:
- MAX_SEV_IR: 0=NO INJURY, 1=INJURY, 2=FATALITY
- Transformar a: INJURY = "yes" si MAX_SEV_IR âˆˆ {1,2}, "no" si MAX_SEV_IR = 0
```

## SoluciÃ³n Paso a Paso

### PASO 1.1: Primeros 12 registros

**Que hacer:**
1. Cargar AccidentsFull.csv
2. Crear variable INJURY
3. Seleccionar primeros 12 registros
4. Usar solo WEATHER_R y TRAF_CON_R como predictores
5. Entrenar Multinomial Naive Bayes
6. Mostrar probabilidades y predicciones
7. Usar threshold = 0.5

**CÃ³digo:**

```python
# Cargar y preparar
accidents_df = pd.read_csv('AccidentsFull.csv')
accidents_df['INJURY'] = accidents_df['MAX_SEV_IR'].apply(
    lambda x: 'yes' if x in [1, 2] else 'no'
)

# Seleccionar primeros 12
sample_12 = accidents_df[['INJURY', 'WEATHER_R', 'TRAF_CON_R']].head(12)

# One-hot encoding
X_12 = pd.get_dummies(sample_12[['WEATHER_R', 'TRAF_CON_R']])
y_12 = sample_12['INJURY']

# Entrenar
nb = MultinomialNB(alpha=0.01)
nb.fit(X_12, y_12)

# Predicciones
proba = nb.predict_proba(X_12)
pred = nb.predict(X_12)

# Mostrar resultados
for i in range(len(X_12)):
    print(f"{i}: P(no)={proba[i,0]:.4f}, P(yes)={proba[i,1]:.4f}, Pred={pred[i]}")
```

**InterpretaciÃ³n esperada:**
- Para cada registro mostrarÃ¡ probabilidades
- Si P(yes) >= 0.5 â†’ predecir "yes"
- Si P(yes) < 0.5 â†’ predecir "no"
- Comparar con valores reales

### PASO 1.2: AnÃ¡lisis completo

**1.2.1 Predictores disponibles:**

```
âœ“ Disponibles ANTES de reportar el accidente:
- WEATHER_R: Condiciones climÃ¡ticas
- TRAF_CON_R: Condiciones de trÃ¡fico
- LGTCON_I_R: Condiciones de luz
- WKDY_I_R: DÃ­a de la semana
- HOUR_I_R: Hora del accidente
- INT_HWY: Tipo de carretera
- SPD_LIM: LÃ­mite de velocidad
```

**1.2.2 Entrenar el modelo:**

```python
# DivisiÃ³n 60/40
X_full = pd.get_dummies(accidents_df[['WEATHER_R', 'TRAF_CON_R']])
y_full = accidents_df['INJURY']

X_train, X_val, y_train, y_val = train_test_split(
    X_full, y_full, test_size=0.4, random_state=1, stratify=y_full
)

# Entrenar
nb_model = MultinomialNB(alpha=0.01)
nb_model.fit(X_train, y_train)

# Evaluar
y_pred = nb_model.predict(X_val)
cm = confusion_matrix(y_val, y_pred, labels=['no', 'yes'])

# Mostrar matriz
print("Matriz de ConfusiÃ³n:")
print(cm)

# Calcular accuracy
accuracy = accuracy_score(y_val, y_pred)
print(f"Accuracy: {accuracy:.4f}")

# Error total
error = 1 - accuracy
print(f"Error Total: {error:.4f}")
```

**InterpretaciÃ³n:**

```
Matriz de ConfusiÃ³n:
           Predicho
       no    yes
Real no  TN    FP
Real yes FN    TP

Accuracy = (TN + TP) / (Total)
â†’ Porcentaje de predicciones correctas

Error = 1 - Accuracy
â†’ Porcentaje de predicciones incorrectas
```

---

# <a name="problema-2"></a>
# PROBLEMA 2: TOYOTA COROLLA PRICES

## Objetivo

Predecir el precio de un Toyota Corolla usado usando RegresiÃ³n Lineal MÃºltiple.

## Datos

```
Dataset: ToyotaCorolla.csv
- 1,436 registros
- 38 atributos
- AÃ±o: 2004 (PaÃ­ses Bajos)

Predictores obligatorios:
Age_08_04, KM, Fuel_Type, HP, Automatic, Doors,
Quarterly_Tax, Mfr_Guarantee, Guarantee_Period,
Airco, Automatic_airco, CD_Player, Powered_Windows,
Sport_Model, Tow_Bar

Variable objetivo: Price
```

## SoluciÃ³n

### PASO 2.1: DivisiÃ³n y Modelo

```python
# Cargar
toyota_df = pd.read_csv('ToyotaCorolla.csv')

# Predictores
predictores = ['Age_08_04', 'KM', 'Fuel_Type', 'HP', 'Automatic', 'Doors',
               'Quarterly_Tax', 'Mfr_Guarantee', 'Guarantee_Period',
               'Airco', 'Automatic_airco', 'CD_Player', 'Powered_Windows',
               'Sport_Model', 'Tow_Bar']

# Limpiar NaN
toyota_clean = toyota_df[['Price'] + predictores].dropna()

# One-hot encoding para Fuel_Type
toyota_encoded = pd.get_dummies(toyota_clean, columns=['Fuel_Type'], drop_first=True)
X_toyota = toyota_encoded.drop('Price', axis=1)
y_toyota = toyota_encoded['Price']

# DivisiÃ³n 70/30
X_train, X_val, y_train, y_val = train_test_split(
    X_toyota, y_toyota, test_size=0.3, random_state=1
)

# Entrenar
lr = LinearRegression()
lr.fit(X_train, y_train)

# Evaluar
r2_train = lr.score(X_train, y_train)
r2_val = lr.score(X_val, y_val)
rmse_val = np.sqrt(mean_squared_error(y_val, lr.predict(X_val)))

print(f"RÂ² Train: {r2_train:.4f}")
print(f"RÂ² Val: {r2_val:.4f}")
print(f"RMSE Val: ${rmse_val:,.2f}")
```

### PASO 2.2: AnÃ¡lisis de Importancia

```python
# Extraer coeficientes
coef_df = pd.DataFrame({
    'Predictor': X_toyota.columns,
    'Coeficiente': lr.coef_,
    'Abs_Coef': np.abs(lr.coef_)
}).sort_values('Abs_Coef', ascending=False)

# Top predictores
print("TOP 3-4 PREDICTORES MÃS IMPORTANTES:")
print(coef_df.head(4))

# InterpretaciÃ³n
for idx, row in coef_df.head(4).iterrows():
    print(f"\n{row['Predictor']}:")
    print(f"  Coeficiente: {row['Coeficiente']:,.2f}")
    if row['Coeficiente'] > 0:
        print(f"  â†’ AUMENTA precio: +${abs(row['Coeficiente']):,.2f} por unidad")
    else:
        print(f"  â†’ DISMINUYE precio: -${abs(row['Coeficiente']):,.2f} por unidad")
```

### InterpretaciÃ³n esperada:

```
Los predictores mÃ¡s importantes son probablemente:
1. Age (edad): Coef < 0 â†’ MÃ¡s viejo = menos precio
2. KM (kilÃ³metros): Coef < 0 â†’ MÃ¡s uso = menos precio
3. HP (potencia): Coef > 0 â†’ MÃ¡s potencia = mÃ¡s precio
4. Automatic (automÃ¡tico): Coef ? â†’ Depende del mercado
```

---

# <a name="problema-3"></a>
# PROBLEMA 3: SPAM DETECTION

## Objetivo

Detectar emails de spam vs no-spam usando Linear Discriminant Analysis con los 11 predictores mÃ¡s discriminativos.

## Datos

```
Dataset: spambase.csv
- 4,601 emails
- 57 predictores (frecuencias de palabras/sÃ­mbolos)
- 1,813 spam (39.4%), 2,788 no-spam (60.6%)

Ãšltima columna: Spam (0=no-spam, 1=spam)
```

## SoluciÃ³n

### PASO 3.1: Seleccionar 11 predictores

**Idea:** Encontrar palabras/sÃ­mbolos que MÃS diferencian spam de no-spam

```python
# Cargar
spam_df = pd.read_csv('spambase.csv')
X_spam = spam_df.drop('Spam', axis=1)
y_spam = spam_df['Spam']

# Calcular diferencias de medias
spam_class = X_spam[y_spam == 1].mean()
nonspam_class = X_spam[y_spam == 0].mean()

diff = np.abs(spam_class - nonspam_class).sort_values(ascending=False)

# Top 11
top_11 = diff.head(11)

print("TOP 11 PREDICTORES QUE DIFERENCIAN SPAM DE NO-SPAM:")
for i, (feat, val) in enumerate(top_11.items(), 1):
    mean_spam = spam_class[feat]
    mean_nonspam = nonspam_class[feat]
    print(f"{i:2d}. {feat:20s} | Spam: {mean_spam:.4f} | No-Spam: {mean_nonspam:.4f} | Diff: {val:.4f}")
```

**InterpretaciÃ³n:**

```
Palabras que aparecen MÃS en SPAM:
- "money", "free", "business", "http", "email"

Palabras que aparecen MÃS en NO-SPAM:
- "george", "data", "lab", "address"

SÃ­mbolos que aparecen MÃS en SPAM:
- "$", "!", "(", "[", ";"
```

### PASO 3.2: Entrenar LDA

```python
# Seleccionar 11 predictores
top_11_preds = diff.head(11).index.tolist()
X_spam_selected = X_spam[top_11_preds]

# DivisiÃ³n
X_train_s, X_val_s, y_train_s, y_val_s = train_test_split(
    X_spam_selected, y_spam, test_size=0.3, random_state=1, stratify=y_spam
)

# Entrenar LDA
lda = LinearDiscriminantAnalysis()
lda.fit(X_train_s, y_train_s)

# Predicciones
y_pred_s = lda.predict(X_val_s)

# Matriz de confusiÃ³n
cm = confusion_matrix(y_val_s, y_pred_s)
print("Matriz de ConfusiÃ³n:")
print(cm)

# MÃ©tricas
tn, fp, fn, tp = cm.ravel()
accuracy = (tp + tn) / (tp + tn + fp + fn)
precision = tp / (tp + fp)
recall = tp / (tp + fn)
specificity = tn / (tn + fp)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"Specificity: {specificity:.4f}")
```

### PASO 3.3: EvaluaciÃ³n del Modelo

**Â¿Es Ãºtil el modelo?**

```
Criterios de utilidad:
âœ“ Accuracy > 70%:    Modelo funciona bÃ¡sicamente
âœ“ Accuracy > 85%:    Modelo bueno
âœ“ Accuracy > 95%:    Modelo excelente

âœ“ Precision > 90%:   Pocos falsos positivos (emails legÃ­timos marcados)
âœ“ Recall > 85%:      Capturamos la mayorÃ­a del spam

RESPUESTA ESPERADA:
"Este modelo IS/NO Ãºtil para detectar spam porque:
- Accuracy = X% (suficiente/insuficiente)
- Precision = X% (pocas/muchas falsas alarmas)
- Recall = X% (detectamos mucho/poco spam real)"
```

---

# <a name="resumen"></a>
# RESUMEN DE EVALUACIÃ“N

## Rubrica del Examen

```
PROBLEMA 1: AUTOMOBILE ACCIDENTS (30 puntos)
â”œâ”€ 1.1 Primeros 12 registros         (10 pts)
â”‚  â”œâ”€ Cargar datos                   (2 pts)
â”‚  â”œâ”€ Crear variable INJURY          (2 pts)
â”‚  â”œâ”€ Aplicar Naive Bayes            (3 pts)
â”‚  â””â”€ Mostrar probabilidades         (3 pts)
â”‚
â””â”€ 1.2 Dataset completo              (20 pts)
   â”œâ”€ DivisiÃ³n 60/40                 (5 pts)
   â”œâ”€ Entrenar NB                    (5 pts)
   â”œâ”€ Matriz de confusiÃ³n            (5 pts)
   â””â”€ Calcular error total           (5 pts)

PROBLEMA 2: TOYOTA COROLLA (35 puntos)
â”œâ”€ 2.1 Modelo de regresiÃ³n           (20 pts)
â”‚  â”œâ”€ DivisiÃ³n 70/30                 (5 pts)
â”‚  â”œâ”€ Entrenar modelo                (5 pts)
â”‚  â”œâ”€ Histogramas de errores         (5 pts)
â”‚  â””â”€ InterpretaciÃ³n                 (5 pts)
â”‚
â””â”€ 2.2 Predictores mÃ¡s importantes   (15 pts)
   â”œâ”€ Identificar top 3-4            (8 pts)
   â””â”€ JustificaciÃ³n                  (7 pts)

PROBLEMA 3: SPAM DETECTION (35 puntos)
â”œâ”€ 3.1 Seleccionar 11 predictores    (12 pts)
â”‚  â”œâ”€ Calcular diferencias           (6 pts)
â”‚  â””â”€ Identificar palabras/sÃ­mbolos  (6 pts)
â”‚
â”œâ”€ 3.2 Entrenar LDA                  (13 pts)
â”‚  â”œâ”€ DivisiÃ³n datos                 (3 pts)
â”‚  â”œâ”€ Modelo LDA                     (5 pts)
â”‚  â””â”€ Predicciones                   (5 pts)
â”‚
â””â”€ 3.3 EvaluaciÃ³n del modelo         (10 pts)
   â”œâ”€ Matriz de confusiÃ³n            (5 pts)
   â””â”€ InterpretaciÃ³n de utilidad     (5 pts)

TOTAL: 100 puntos
```

---

# <a name="preguntas"></a>
# PREGUNTAS DE EXAMEN PROBABLE

## Pregunta TeÃ³rica 1

**"Â¿Por quÃ© es importante crear la variable INJURY (sÃ­/no) en lugar de usar directamente MAX_SEV_IR (0, 1, 2)?"**

**Respuesta esperada:**
```
El problema requiere clasificaciÃ³n BINARIA (lesiÃ³n sÃ­/no), no multiclase.

MAX_SEV_IR = 0: Sin lesiÃ³n
MAX_SEV_IR = 1: LesiÃ³n moderada
MAX_SEV_IR = 2: Fatality

Para predicciÃ³n rÃ¡pida en reportes iniciales, interesa saber:
Â¿Hay lesiÃ³n o no? (sÃ­/no)

No importa diferenciar entre lesiÃ³n moderada y fatality en tiempo real.

INJURY = "yes" si MAX_SEV_IR âˆˆ {1, 2}
INJURY = "no" si MAX_SEV_IR = 0
```

## Pregunta TeÃ³rica 2

**"Â¿Por quÃ© Multinomial Naive Bayes requiere datos discretos?"**

**Respuesta esperada:**
```
Multinomial Naive Bayes estima:

P(caracterÃ­stica | clase) = (conteos de caracterÃ­stica en clase) / (total de conteos)

Si la caracterÃ­stica es CONTINUA (ej: edad = 34.567 aÃ±os):
- PrÃ¡cticamente nunca se repetirÃ¡ exactamente 34.567 en validation
- Conteos en training = quizÃ¡s 1 o 0
- EstimaciÃ³n = muy poco confiable
- P(edad=34.567 | retraso) = casi imposible de calcular

SOLUCIÃ“N: Convertir a discreta (binning) o usar GaussianNB
```

## Pregunta PrÃ¡ctica 1

**"Â¿CuÃ¡l fue la matrix de confusiÃ³n para el problema de accidentes? Interprete cada valor."**

**Respuesta esperada:**
```
Matriz tÃ­pica esperada:
         Predicho
       no    yes
Real no  TN    FP
Real yes FN    TP

InterpretaciÃ³n:
- TN (True Negative): Accidentes sin lesiÃ³n predichos correctamente
- FP (False Positive): Sin lesiÃ³n pero predijo que hay (falsa alarma)
- FN (False Negative): Con lesiÃ³n pero predijo que no (riesgo!)
- TP (True Positive): Con lesiÃ³n predichos correctamente

Error Total = (FP + FN) / Total

En contexto de seguridad: FN es mÃ¡s peligroso que FP
(mejor alarma falsa que no detectar lesiÃ³n real)
```

## Pregunta PrÃ¡ctica 2

**"Â¿CuÃ¡les fueron los 3 principales predictores del precio en Toyota Corolla? Â¿Por quÃ©?"**

**Respuesta esperada:**
```
Esperados (basado en lÃ³gica):

1. Age_08_04 (edad): Coef â‰ˆ -500 a -1000
   â†’ Autos mÃ¡s viejos valen MENOS
   â†’ DepreciaciÃ³n obvia

2. KM (kilÃ³metros): Coef â‰ˆ -1 a -5
   â†’ MÃ¡s uso = menos precio
   â†’ Desgaste acumulado

3. HP (potencia): Coef â‰ˆ 50 a 200
   â†’ MÃ¡s potencia = mÃ¡s precio
   â†’ Mayor capacidad = valor

Estos son intuitivos porque:
- Edad: Factor fundamental de depreciaciÃ³n
- Km: Indicador de desgaste
- HP: Indicador de calidad/prestaciones
```

## Pregunta PrÃ¡ctica 3

**"Â¿Fue Ãºtil el modelo LDA para detectar spam? Justifique."**

**Respuesta esperada:**
```
Criterios de utilidad:

SI es Ãºtil si:
âœ“ Accuracy > 80%
âœ“ Precision > 85% (pocos emails legÃ­timos marcados como spam)
âœ“ Recall > 75% (detectamos mayorÃ­a de spam)

NO es Ãºtil si:
âœ— Accuracy < 70%
âœ— Precision < 70% (falsas alarmas altas)
âœ— Recall < 60% (mucho spam se cuela)

Respuesta esperada:
"El modelo [SÃ/NO] es Ãºtil porque:
- Accuracy = X%
- Precision = X% (significado: de cada 100 emails que predije como spam, X eran reales)
- Recall = X% (significado: de cada 100 spam reales, detectÃ© X)
- En conclusiÃ³n: [beneficio/inconveniente]"
```

---

## Checklist Antes del Examen

```
â–¡ Entiendo por quÃ© Naive Bayes necesita datos discretos
â–¡ Puedo crear variable INJURY correctamente
â–¡ SÃ© cÃ³mo dividir datos en train/validation
â–¡ Puedo interpretar una matriz de confusiÃ³n
â–¡ Conozco la diferencia entre Accuracy y Error
â–¡ Entiendo RÂ² e RMSE en regresiÃ³n
â–¡ Puedo identificar predictores importantes
â–¡ SÃ© cÃ³mo calcular diferencias de medias
â–¡ Entiendo cuÃ¡ndo un modelo de clasificaciÃ³n es Ãºtil
â–¡ He practicado cada problema al menos una vez
```

---

**Documento de Estudio Completo - Examen Parcial CC442**  
**MinerÃ­a de Datos (8vo Ciclo) - 2025**
