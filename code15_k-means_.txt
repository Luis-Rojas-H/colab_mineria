import pandas as pd
from sklearn import preprocessing
from sklearn.metrics import pairwise
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from sklearn.cluster import KMeans
import matplotlib.pylab as plt
import seaborn as sns
from pandas.plotting import parallel_coordinates

# Load and preprocess data
utilities_df = pd.read_csv("/content/Utilities.csv")
# utilities_df.dtypes
# utilities_df.shape
# utilities_df.head()

utilities_df.set_index("Company", inplace=True)
utilities_df = utilities_df.apply(lambda x: x.astype("float64"))
# Normalize distances
utilities_df_norm = utilities_df.apply(preprocessing.scale,axis=0)
# utilities_df_norm.dtypes
kmeans = KMeans(n_clusters=6, random_state=0).fit(utilities_df_norm)
# Cluster membership
memb = pd.Series(kmeans.labels_, index=utilities_df_norm.index)
for key, item in memb.groupby(memb):
	print(key, ": ", ", ".join(item.index))

# centroids
centroids = pd.DataFrame(kmeans.cluster_centers_,columns=utilities_df_norm.columns)
#pd.set_option("precision", 3)
centroids

# Within-cluster sum of squared distances and cluster count
# calculate the distances of each data point to the cluster centers
distances = kmeans.transform(utilities_df_norm)
pd.DataFrame(distances)
# find closest cluster for each data point
minSquaredDistances = distances.min(axis=1) ** 2
# combine with cluster labels into a data frame
df = pd.DataFrame({'squaredDistance': minSquaredDistances,'cluster': kmeans.labels_},index=utilities_df_norm.index)
# group by cluster and print information
for cluster, data in df.groupby("cluster"):
	count = len(data)
	withinClustSS = data.squaredDistance.sum()
	print(f'Cluster', cluster, '(',count,'members)', 'squaredDistanceSum:',withinClustSS, 'within', cluster)

# Euclidean Distance between Cluster centroids
pd.DataFrame(pairwise.pairwise_distances(kmeans.cluster_centers_,metric='euclidean'))


# code for plotting profile plot of centroids
centroids['cluster'] = [format(i) for i in centroids.index]
plt.figure(figsize=(10,6))
parallel_coordinates(centroids, class_column='cluster',colormap='Dark2', linewidth=5)
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))

# code for average withincluster distance vs number of cluster
inertia = []
for n_clusters in range(1, 7):
	kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(utilities_df_norm)
	inertia.append(kmeans.inertia_ / n_clusters)
inertias = pd.DataFrame({'n_clusters': range(1, 7), 'inertia':inertia})
ax = inertias.plot(x='n_clusters', y='inertia')
plt.xlabel('Number of clusters (k)')
plt.ylabel('Average Within-Cluster Squared Distances')
plt.ylim((0, 1.1 * inertias.inertia.max()))
ax.legend().set_visible(False)
plt.show()


