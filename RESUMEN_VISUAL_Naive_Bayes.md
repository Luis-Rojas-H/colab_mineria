# ğŸ“Š RESUMEN VISUAL: Multinomial Naive Bayes

## ğŸ”„ FLUJO DEL ALGORITMO

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          FLUJO MULTINOMIAL NAIVE BAYES                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. DATOS CRUDOS
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ FlightDelays.csv        â”‚
   â”‚ 2203 vuelos Ã— 13 cols   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
2. PREPARACIÃ“N DE DATOS
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ âœ“ Categorizar variables     â”‚
   â”‚ âœ“ Crear bins horarios       â”‚
   â”‚ âœ“ One-hot encoding          â”‚
   â”‚ âœ“ Seleccionar predictores   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
3. DIVISIÃ“N TRAIN/TEST (60/40)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   TRAINING       â”‚   VALIDATION     â”‚
   â”‚  1321 muestras   â”‚  882 muestras    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                  â”‚
            â–¼                  â”‚
4. ENTRENAMIENTO                â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
   â”‚ MultinomialNB(alpha=0.01)â”‚ â”‚
   â”‚ - Calcula P(predictor|clase)
   â”‚ - Calcula P(clase)       â”‚ â”‚
   â”‚ - Almacena probabilidadesâ”‚ â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
            â”‚                   â”‚
            â–¼                   â”‚
5. PREDICCIÃ“N EN VALIDACIÃ“N     â”‚
   â”œâ”€â†’ predict() â†’ ['ontime', 'delayed', ...] 
   â””â”€â†’ predict_proba() â†’ [[0.75, 0.25], ...]
                         â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
6. EVALUACIÃ“N
   â”œâ”€ Accuracy: 80.5%
   â”œâ”€ Matriz de confusiÃ³n
   â””â”€ AnÃ¡lisis de errores
```

---

## ğŸ§® FÃ“RMULA MATEMÃTICA

```
                    P(xâ‚|y) Ã— P(xâ‚‚|y) Ã— ... Ã— P(xâ‚™|y) Ã— P(y)
P(y | xâ‚, xâ‚‚, ..., xâ‚™) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                               P(xâ‚, xâ‚‚, ..., xâ‚™)

Donde:
  y = clase (ontime / delayed)
  xâ‚, xâ‚‚, ..., xâ‚™ = features (DAY_WEEK, CARRIER, etc.)
```

**InterpretaciÃ³n para nuestro caso:**
```
P(ontime | CARRIER=DL, DAY_WEEK=7, CRS_DEP_TIME=10, DEST=LGA, ORIGIN=DCA)
= P(DL|ontime) Ã— P(7|ontime) Ã— P(10|ontime) Ã— P(LGA|ontime) Ã— P(DCA|ontime) Ã— P(ontime)
```

---

## ğŸ“Š TRANSFORMACIÃ“N DE DATOS

### One-Hot Encoding Ejemplo

```
ORIGINAL:                 ONE-HOT ENCODED:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CARRIER  â”‚      â†’      â”‚ CARRIER_AA  CARRIER_DL  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   DL     â”‚             â”‚    0            1       â”‚
â”‚   AA     â”‚             â”‚    1            0       â”‚
â”‚   DL     â”‚             â”‚    0            1       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Bins Horarios

```
ORIGINAL TIME: 1455 (14:55)
       â†“
   1455 / 100 = 14.55
       â†“
   round(14.55) = 15 horas (3 PM)
       â†“
CATEGORIZADO: 15
```

---

## ğŸ¯ TABLA DE PROBABILIDADES CONDICIONALES

**Ejemplo: Â¿QuÃ© dÃ­a tiene mÃ¡s retrasos?**

```
                DAY_WEEK (1=Lunes, 7=Domingo)
             â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
             â”‚  1   â”‚  2   â”‚  3   â”‚  4   â”‚  5   â”‚  6   â”‚  7   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ P(ontime)  â”‚ 0.65 â”‚ 0.64 â”‚ 0.62 â”‚ 0.63 â”‚ 0.65 â”‚ 0.60 â”‚ 0.58 â”‚ â† Domingo tiene MENOS
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ P(delayed) â”‚ 0.35 â”‚ 0.36 â”‚ 0.38 â”‚ 0.37 â”‚ 0.35 â”‚ 0.40 â”‚ 0.42 â”‚ â† Domingo tiene MÃS
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

CONCLUSIÃ“N: Vuelos el domingo (7) tienen MAYOR probabilidad de retraso (42%)
```

---

## ğŸ” PREDICCIÃ“N PASO A PASO

```
NUEVO VUELO:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CARRIER: Delta (DL)          â”‚
â”‚ DAY_WEEK: Domingo (7)        â”‚
â”‚ CRS_DEP_TIME: 15:00 (15 hrs) â”‚
â”‚ DEST: LaGuardia (LGA)        â”‚
â”‚ ORIGIN: Reagan (DCA)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
MODEL PREDICTIONS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ P(ontime) = 0.35             â”‚ (35% posibilidad)
â”‚ P(delayed) = 0.65            â”‚ (65% posibilidad)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
PREDICCIÃ“N FINAL:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLASE: DELAYED   â”‚ â† Probabilidad mÃ¡s alta
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… MATRIZ DE CONFUSIÃ“N

```
                    PREDICCIÃ“N
                 ontime  delayed
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
REAL ontime  â”‚   TP=400 â”‚ FN=100  â”‚  (500 reales ontime)
             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     delayed â”‚   FP=50  â”‚ TN=332  â”‚  (382 reales delayed)
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CÃ¡lculos:
â”œâ”€ Accuracy = (TP + TN) / Total = (400 + 332) / 882 = 83%
â”œâ”€ Precision = TP / (TP + FP) = 400 / 450 = 88.9%
â””â”€ Recall = TP / (TP + FN) = 400 / 500 = 80%
```

---

## ğŸ†š COMPARACIÃ“N: SparsePCA vs Multinomial NB

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CARACTERÃSTICA      â”‚  SparsePCA     â”‚ Multinomial Naive   â”‚
â”‚                     â”‚                â”‚      Bayes          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tipo                â”‚ ReducciÃ³n dim. â”‚ ClasificaciÃ³n       â”‚
â”‚ Input               â”‚ Continuos      â”‚ CategÃ³ricos (ideales)
â”‚ Output              â”‚ Componentes    â”‚ Predicciones        â”‚
â”‚ Objetivo            â”‚ ExploraciÃ³n    â”‚ PredicciÃ³n          â”‚
â”‚ Datos discretos OK  â”‚ âŒ NO         â”‚ âœ… SÃ              â”‚
â”‚ Complejidad         â”‚ Media          â”‚ Baja                â”‚
â”‚ Interpretable       â”‚ Medio          â”‚ Alto                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš¨ PROBLEMAS COMUNES Y SOLUCIONES

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROBLEMA: Probabilidades cero                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CAUSA: Un valor nunca aparece en training             â”‚
â”‚ EJEMPLO: Si aerolÃ­nea 'XYZ' no aparece en train,      â”‚
â”‚          P(XYZ) = 0 siempre                           â”‚
â”‚ SOLUCIÃ“N: Usar alpha > 0 (Laplace Smoothing)         â”‚
â”‚ EN CÃ“DIGO: MultinomialNB(alpha=0.01)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROBLEMA: Overfitting                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CAUSA: Entrenar y probar con MISMOS datos             â”‚
â”‚ RESULTADO: Accuracy alto en train, bajo en test       â”‚
â”‚ SOLUCIÃ“N: Dividir en train/validation (60/40)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROBLEMA: Variables categÃ³ricas vs numÃ©ricas          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CAUSA: MultinomialNB espera nÃºmeros, recibe textos    â”‚
â”‚ SOLUCIÃ“N: One-hot encoding con pd.get_dummies()      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ CONCEPTOS CLAVE EXPLICADOS

### **Â¿QuÃ© es "Naive"?**
```
Naive = INGENUO

Se llama "ingenuo" porque ASUME que todos los
predictores son INDEPENDIENTES entre sÃ­:

Realidad:          AsunciÃ³n Naive:
CARRIER_DL â”€â”€â”€â”   CARRIER_DL â”¬ independiente
              â”œâ”€ Correlacionadas
DAY_WEEK_7 â”€â”€â”€â”˜               â”‚
              â””â”€ DAY_WEEK_7 independiente

Aunque la asunciÃ³n es FALSA, el algoritmo funciona
sorprendentemente bien en la prÃ¡ctica.
```

### **Â¿QuÃ© es Laplace Smoothing (alpha)?**
```
SIN Smoothing (alpha=0):
  P(nunca_visto) = 0 â† PROBLEMA: No puedes predecir

CON Smoothing (alpha=0.01):
  P(nunca_visto) = 0.01 â† OK: PequeÃ±a probabilidad
  
MÃ¡s alto alpha â†’ MÃ¡s suavizado
  alpha=1.0 â†’ Muy suavizado
  alpha=0.01 â†’ Poco suavizado
```

### **Â¿QuÃ© es One-Hot Encoding?**
```
ANTES:          DESPUÃ‰S:
CARRIER         CARRIER_AA  CARRIER_DL  CARRIER_OH
DL      â†’            0           1           0
AA              â†’    1           0           0
OH              â†’    0           0           1

VENTAJA: MultinomialNB necesita nÃºmeros (0/1)
DESVENTAJA: Aumenta nÃºmero de columnas
```

---

## ğŸ“‹ CHECKLIST ANTES DEL EXAMEN

- [ ] Entiendo la fÃ³rmula del Teorema de Bayes
- [ ] Puedo explicar por quÃ© "ingenuo"
- [ ] SÃ© quÃ© es Laplace Smoothing
- [ ] Entiendo One-Hot Encoding
- [ ] Puedo leer una tabla de probabilidades condicionales
- [ ] SÃ© interpretar una matriz de confusiÃ³n
- [ ] Entiendo por quÃ© train/test split es importante
- [ ] Puedo explicar predict() vs predict_proba()
- [ ] SÃ© diferenciar SparsePCA de Multinomial NB
- [ ] Puedo ejecutar el cÃ³digo sin errores

---

## ğŸ¯ PREGUNTAS DE EXAMEN PROBABLE

```
P1: Â¿Por quÃ© se llama "Naive"?
R: Porque asume independencia entre predictores

P2: Â¿QuÃ© hace pd.get_dummies()?
R: Convierte categorÃ­as en variables binarias (0/1)

P3: Â¿CuÃ¡l es la diferencia entre predict() y predict_proba()?
R: predict() â†’ clase ganadora
   predict_proba() â†’ todas las probabilidades

P4: Â¿Por quÃ© importa train_test_split?
R: Para evitar overfitting y evaluar en datos nuevos

P5: Â¿QuÃ© es alpha en MultinomialNB(alpha=0.01)?
R: Laplace Smoothing para evitar P=0

P6: Â¿QuÃ© diferencia hay con SparsePCA?
R: SparsePCA explora (dimensionalidad), NB predice (clasificaciÃ³n)

P7: Â¿QuÃ© significa P(ontime | CARRIER=DL)?
R: Probabilidad de llegar a tiempo DADO que es Delta Airlines
```

---

**Ahora tienes una comprensiÃ³n completa de Multinomial Naive Bayes** âœ…

